{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"><center>Exercise III:<br> Convolutional and Recurrent Neural Networks\n",
    "</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short summary\n",
    "In this exercise you will: \n",
    "\n",
    "* Train CNNs for a binary classification problem\n",
    "* Visualize how CNNs interprets the data\n",
    "* Train CNNs for two 3-class classification problem\n",
    "* Train a RNN on a time series prediction problem\n",
    "* Visualize RNN hidden node activities\n",
    "\n",
    "In this lab we will look at network architectures that are designed to handle specific kinds of data. Convolutional Neural Networks for image processing and Recurrent Neural Networks for time series processing\n",
    "\n",
    "**Deadline for submitting the report: See Canvas assignment.**\n",
    "\n",
    "## The data\n",
    "Digits \"5\" and \"6\" from the MNIST database used for a binary classification problem.\n",
    "\n",
    "A dataset consisting of circles, rectangles or triangles, that can be read using the *loadImagesCRT* function.\n",
    "\n",
    "A dataset consisting of three different types of rectangles, squares, \"horizontal\" rectangles and \"vertical\" rectangles. This data can be read using the *loadImagesR3* function.\n",
    "\n",
    "A dataset consisting of pairs of times series. The input time series is a train of rectangle pulses, and the output is triangles, i.e. an up-ramp followed by a down-ramp. For more details see the cell *Ex4-1*. The task is to train a recurrent network that predicts the triangle time series from the pulse time series.\n",
    "\n",
    "\n",
    "## The exercises\n",
    "As for the previous labs all exercises are found below.\n",
    "\n",
    "## The different 'Cells'\n",
    "This notebook contains several cells with python code, together with the markdown cells (like this one) with only text. Each of the cells with python code has a \"header\" markdown cell with information about the code. The table below provides a short overview of the code cells. \n",
    "\n",
    "| #  |  CellName | CellType | Comment |\n",
    "| :--- | :-------- | :-------- | :------- |\n",
    "| 1 | Init | Needed | Sets up the environment|\n",
    "| 2 | Data | Needed | Loading images for the CNN exercise |\n",
    "| 3 | PlotImg | Information  | View some of the images |\n",
    "| 4 | Stats | Needed | Compute classification results |\n",
    "| 5 | Visualization | Needed | Visualize layers of a CNN |\n",
    "| 6 | Ex1 | Exercise | For question 1-2 |\n",
    "| 7 | Ex2 | Exercise | For question 3 |\n",
    "| 8 | Ex3 | Exercise | For question 4-5 |\n",
    "| 9 | Ex4-1 | Exercise | For question 6-9 |\n",
    "| 10 | Ex4-2 | Exercise | For question 6-9 |\n",
    "| 11 | Ex4-3 | Exercise | For question 6-9 |\n",
    "\n",
    "\n",
    "In order for you to start with the exercise you need to run all cells with the CellType \"Needed\". The very first time you start with this exercise we suggest that you enter each of the needed cells, read the cell instruction and run the cell. It is important that you do this in the correct order, starting from the top and work you way down the cells. Later when you have started to work with the notebook it may be easier to use the command \"Run All\" found in the \"Cell\" dropdown menu.\n",
    "\n",
    "## Writing the report\n",
    "First the report should be written within this notebook. We have prepared the last cell in this notebook for you where you should write the report. The report should contain 4 parts:\n",
    "\n",
    "* Name:\n",
    "* Introduction: A **few** sentences where you give a small introduction of what you have done in the lab.\n",
    "* Answers to questions: For each of the questions provide an answer. It can be short answers or a longer ones depending on the nature of the questions, but try to be effective in your writing.\n",
    "* Conclusion: Summarize your findings in a few sentences.\n",
    "\n",
    "It is important that you write the report in this last cell and **not** after each question! \n",
    "\n",
    "## Last but not least\n",
    "Have fun again!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Init (#1)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Initializing the libraries\n",
    "In the cell below, we import all the libraries that are needed for this exercises. \n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Lambda, concatenate\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, RNN\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Nadam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Data (#2)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Function for getting images for the CNN exercises\n",
    "\n",
    "This cell defines the functions that obtain the images needed for the CNN exercise. **Note**: Make sure the \"crt-trn/\" and \"crt-tst/\" folders are available in the same directory as this notebook file when you actually call these functions. Otherwise, the files files are not found.\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pics(folder,N):\n",
    "    import imageio.v2 as imageio\n",
    "    imgs = []\n",
    "    for i in range(N):\n",
    "        img = imageio.imread(folder+\"img_{:05}.png\".format(i+1))\n",
    "        ch = img[:,:,0]\n",
    "        imgs.append(ch)\n",
    "    return np.array(imgs)\n",
    "\n",
    "def load_labels(fn):\n",
    "    return np.loadtxt(fn, usecols=(0,1,2))\n",
    "\n",
    "def loadImagesCRT():\n",
    "    base = \"./\"\n",
    "    trainpic = load_pics(base + \"crt-trn/\", 500)\n",
    "    valpic = load_pics(base + \"crt-val/\", 1000)\n",
    "    ntrain, width, height = trainpic.shape\n",
    "\n",
    "    xtrain = (trainpic/np.float32(255)).reshape(500, width, height, 1)\n",
    "    xval = (valpic/np.float32(255)).reshape(1000, width, height, 1)\n",
    "\n",
    "    ytrain = load_labels(base+\"crt-trn_trg.csv\")\n",
    "    #ytrain = ytrain[:N]\n",
    "    yval = load_labels(base+\"crt-val_trg.csv\")\n",
    "    \n",
    "    return xtrain, ytrain, xval, yval, width, height\n",
    "\n",
    "def loadImagesR3():\n",
    "    base = \"./\"\n",
    "    trainpic = load_pics(base + \"r3-trn/\", 500)\n",
    "    valpic = load_pics(base + \"r3-val/\", 1000)\n",
    "    ntrain, width, height = trainpic.shape\n",
    "\n",
    "    xtrain = (trainpic/np.float32(255)).reshape(500, width, height, 1)\n",
    "    xval = (valpic/np.float32(255)).reshape(1000, width, height, 1)\n",
    "\n",
    "    ytrain = load_labels(base+\"r3-trn_trg.csv\")\n",
    "    #ytrain = ytrain[:500]\n",
    "    yval = load_labels(base+\"r3-val_trg.csv\")\n",
    "\n",
    "    return xtrain, ytrain, xval, yval, width, height\n",
    "\n",
    "\n",
    "def loadMNIST56():\n",
    "    xtrain, ytrain, xval, yval = np.load(\"mnist56.npy\", allow_pickle=True)\n",
    "    width, height = xtrain.shape[1:3]\n",
    "    return xtrain, ytrain, xval, yval, width, height\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: PlotImg (#3)\n",
    "### CellType: Information\n",
    "### Cell instruction: Show some of the images\n",
    "\n",
    "Here we look at the first ten pictures in the training set, and their respective targets. You can select the dataset to look at by uncomment the correct line.\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "xTrn, dTrn, xVal, dVal, width, height = loadMNIST56()\n",
    "#xTrn, dTrn, xVal, dVal, width, height = loadImagesCRT()\n",
    "#xTrn, dTrn, xVal, dVal, width, height = loadImagesR3()\n",
    "\n",
    "rndSel = np.random.randint(500, size=10)\n",
    "plt.figure(1, figsize=(15,10))\n",
    "plt.imshow(xTrn[rndSel,:,:].swapaxes(0,1).reshape(width,10*height),cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Targets:\")\n",
    "print(dTrn[rndSel])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Stats (#4)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Get binary and 3-class classification results\n",
    "\n",
    "This cell just defines functions that we can call to compute som performance measures for binary and 3-class classification problems.\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_pred_stats(ytrue, ypred, threshold=0.5):\n",
    "    one_correct = np.sum((ytrue==1)*(ypred > threshold))\n",
    "    zero_correct = np.sum((ytrue==0)*(ypred <= threshold))\n",
    "    sensitivity = one_correct / np.sum(ytrue==1)\n",
    "    specificity = zero_correct / np.sum(ytrue==0)\n",
    "    accuracy = (one_correct + zero_correct) / len(ytrue)\n",
    "    return sensitivity, specificity, accuracy\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    #plt.ylim([-0.5, cm.shape[0]-0.5])\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "def multi_stat_3(model = None, x_test = None, y_test = None, lbl = None):\n",
    "    y_pred = model.predict(x_test, verbose=0 )\n",
    "    print(lbl,' log_loss:  ', log_loss(y_test, y_pred))\n",
    "\n",
    "    y_true = y_test.argmax(axis=1)\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    print(lbl, ' accuracy:  ',(y_pred==y_true).mean(), '\\n')\n",
    "\n",
    "    target_names = ['class {}'.format(i+1) for i in range(3)]\n",
    "\n",
    "    confuTst = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm           = confuTst, \n",
    "                          normalize    = False,\n",
    "                          target_names = target_names,\n",
    "                          title        = \"Confusion Matrix: \" + lbl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Visualization (#5)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Function that can visualize the different layers of a CNN\n",
    "\n",
    "This cell is feeding an image through a CNN and stores the intemediate values. It plots the different layers (filtered images) either before or after maxpooling.\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerVisaliztion(model,\n",
    "                     indata,\n",
    "                     target,\n",
    "                     idx=10,\n",
    "                     post_pool = False):\n",
    "\n",
    "    # The prediction for the test case\n",
    "    #idx_pred = model.predict(indata)[idx,0]\n",
    "    #print('True label: = {:0.1f}, Prediction = {:0.8f}'.format(idx_pred, target[idx]))\n",
    "    \n",
    "    print('Prediction: ', model.predict(indata, verbose=0)[idx])\n",
    "    print('Target    : ', target[idx])\n",
    "    \n",
    "    kind = MaxPooling2D if post_pool else Conv2D\n",
    "    outs = [l.output for l in model.layers if isinstance(l, kind)]\n",
    "    intermediate = K.function([model.layers[0].input], outs)\n",
    "    \n",
    "    states = [indata[idx:idx+1]] + intermediate([indata[idx:idx+1]])\n",
    "    plt.figure(figsize=(18,12))                    \n",
    "    for k,s in enumerate(states):\n",
    "        plt.figure(figsize=(18,12))\n",
    "        plt.subplot(len(outs)+1,1,k+1)\n",
    "        pics = s[0]\n",
    "        pics = np.rollaxis(pics,2,0)\n",
    "        rows = 2 if pics.shape[0] > 8 else 1\n",
    "        cols = pics.shape[0]//rows\n",
    "        pad = pics.shape[0]-rows*cols\n",
    "        if pad > 0:\n",
    "            padding = np.zeros_like(pics, shape=(rows-pad,)+pics.shape[1:])\n",
    "            pics = np.concatenate([pics, padding])\n",
    "            cols = cols + 1            \n",
    "        imgshape = pics.shape[1:]\n",
    "        pics = pics.reshape((rows,cols)+imgshape)\n",
    "        pics = pics.swapaxes(1,2)\n",
    "        pics = pics.reshape((pics.shape[0]*pics.shape[1], pics.shape[2]*pics.shape[3]))\n",
    "        extent = (0,cols*imgshape[0], 0,rows*imgshape[1])\n",
    "        plt.imshow(pics,cmap='gray',extent=extent)\n",
    "        for r in range(1,rows):\n",
    "            plt.plot([0,cols*imgshape[0]], [r*imgshape[1], r*imgshape[1]], color='r', linestyle='-', linewidth=1)\n",
    "        for c in range(1,cols):\n",
    "            plt.plot([c*imgshape[0], c*imgshape[0]], [0,rows*imgshape[1]], color='r', linestyle='-', linewidth=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex1 (#6)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 1-2\n",
    "\n",
    "## CNN for image classification\n",
    "\n",
    "In this first exercise you are going to train a CNN that can separate between numbers \"5\" and \"6\" from the mnist dataset (mnist56 dataset). We are going to use 2000 training images and 1850 validation images. To start with we have a proposed CNN that can solve this problem. It consists of the following:\n",
    "* First convolutional layer consisting of 4 kernels of size 3x3, with ReLU activation\n",
    "* Maxpooling of size 2x2\n",
    "* Second convolutional layer of 4 kernels of size 3x3, with ReLU activation\n",
    "* Maxpooling of size 2x2\n",
    "* Special layer *Flatten()*, just transforms the all of the max pooled filter outputs to a linear vector of outputs\n",
    "* *Dense* layer, meaning a fully connected MLP layer, to 10 hidden nodes, again ReLU activation\n",
    "* Final output layer consisting of one single output node with sigmoid activation function because we have a binary classification problem.\n",
    "\n",
    "The default is to use *stride* = 1 and no *padding*. \n",
    "\n",
    "#### Question 1\n",
    "Make sure you understand the definition of the CNN model in the cell below and train it. **What is your validation set performance in terms of the accuracy?**\n",
    "\n",
    "#### Question 2\n",
    "This image classification problem should be relatively easy since a \"5\" has some distinct differences from a \"6\". Experiment with the architecture of the CNN model and try to make it smaller (in terms of the number of trainable parameters), but with the same almost perfect validation accuracy (>98%). **How many parameters do you have in your trimmed model? What is your architecture?**\n",
    "\n",
    "**Hint:** There is of course very many ways you can make a smaller architecture. You do not need to test all of them!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, MNIST-56\n",
    "x_trn, d_trn, x_val, d_val, width, height = loadMNIST56()\n",
    "\n",
    "# The size of the images\n",
    "input_shape = (width, height, 1)\n",
    "\n",
    "# Define the CNN ex1\n",
    "ex1 = Sequential()\n",
    "\n",
    "# First conv layer\n",
    "ex1.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "ex1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second conv layer\n",
    "ex1.add(Conv2D(4, kernel_size=(3, 3), activation='relu'))\n",
    "ex1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Fully connected MLP layers\n",
    "ex1.add(Flatten())\n",
    "ex1.add(Dense(10, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "ex1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# We use cross entropy error and the adam optimizer\n",
    "adam = Adam(learning_rate=0.005)\n",
    "ex1.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "ex1.summary()\n",
    "\n",
    "# Now train the ex1\n",
    "estimator_ex1 = ex1.fit(x_trn, d_trn, \n",
    "                        validation_data=(x_val, d_val),\n",
    "                        epochs=30, \n",
    "                        batch_size=64,\n",
    "                        verbose=0)\n",
    "\n",
    "\n",
    "# Training history\n",
    "plt.figure()\n",
    "plt.ylabel('Loss / Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "for k in estimator_ex1.history.keys():\n",
    "    plt.plot(estimator_ex1.history[k], label = k) \n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Get the training predictions and results for those\n",
    "d_trn_pred = ex1.predict(x_trn, verbose=0)[:,0]\n",
    "sens, spec, acc = binary_pred_stats(d_trn, d_trn_pred)\n",
    "print('training: Accuracy = {:.4f}, Sensitivity = {:.4f}, Specificity = {:.4f}'.format(acc, sens, spec), '\\n')\n",
    "\n",
    "# Get the validation predictions and the results for those\n",
    "d_val_pred = ex1.predict(x_val, verbose=0)[:,0]\n",
    "sens, spec, acc = binary_pred_stats(d_val, d_val_pred)\n",
    "print('validation: Accuracy = {:.4f}, Sensitivity = {:.4f}, Specificity = {:.4f}'.format(acc, sens, spec), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex2 (#7)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 3\n",
    "\n",
    "You are now going to take a look into the CNN model. There are many attempts to visualize how the CNN model is making classifications. We will here just look at the different layer outputs given an input image. The function 'layerVisualization', found in cell #5 does the following:\n",
    "* Use one selected image from the supplied dataset.\n",
    "* Make a forward pass through the CNN remembering all intermediate values.\n",
    "* Plot all of the \"filters\" for each of the layers.\n",
    "* One can select to plot before or after the MaxPooling.\n",
    "\n",
    "You pass the model that you want to visualize to the 'layerVisualization' function. If you do not change the names in cell (Ex1) it will be 'ex1'.\n",
    "\n",
    "#### Question 3\n",
    "Train a CNN for the \"5\" vs \"6\" problem! As a suggestion use the following CNN\n",
    "\n",
    "*3x(3x3 kernel)-maxpool-3x(3x3 kernel)-maxpool-(Flatten)-Dense(5)-Dense(1)*\n",
    "\n",
    "Make sure that your trained model gives good validation results (i.e. > 95% accuracy). Having such a model, you can run the cell below. There are two parameters you need to specify, *idx* and *post_pool*. The *post_pool* variable can be set to *True* meaning that filters will be shown after MaxPooling. The image to show is selected by the *idx* variable. As an example, the following values represent,\n",
    "* idx=1 number \"6\"\n",
    "* idx=2 number \"5\"\n",
    "* idx=3 another number \"6\"\n",
    "* idx=5 antoher number \"5\"\n",
    "\n",
    "**Can you find and describe some property in the filters that makes sense when it comes to separating \"5\" from \"6\"?**\n",
    "\n",
    "Hint! If you repeat the training you most likely get a new network and other filters!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show before or after MaxPooling\n",
    "post_pool = False\n",
    "\n",
    "# The test image to look at\n",
    "idx = 1\n",
    "\n",
    "# Call the visualization method, giving the model and the validation data to select the case from\n",
    "layerVisaliztion(ex1, x_val, d_val, idx, post_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex3 (#8)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 4-5\n",
    "\n",
    "## CNN for image classification\n",
    "\n",
    "In this exercise you are going to train a CNN that can separate between circles/squares/triangles found in the CRT dataset, and the three different types of rectangles found in the R3 dataset. You will use 500 training images and 1000 validation images. Code is provided for loading the data, training the model and presenting the result. Your task is to define the actual CNN model and see how it performs. For the following two questions you can optimize the model based on the validation performance. Here we assume that 1000 validation images are many enough for \"model selection overtraining bias\" to be small.\n",
    "\n",
    "#### Question 4\n",
    "Define your own CNN model for classifying the images in the CRT data into three classes. **Provide the details of your CNN model and present the validation result.**\n",
    "\n",
    "**Hint:** Remember the difference between a binary classifier and a multi-class classifier!\n",
    "\n",
    "\n",
    "#### Question 5\n",
    "Define your own CNN model for classifying the images in the R3 data into three classes. **Provide the details of your CNN model and present the validation result.** **Why is this a more difficult problem than Question 4?**\n",
    "\n",
    "\n",
    "#### Bonus task \n",
    "The bonus tasks are provided if you have extra time and want to continue to explore the CNNs. **These tasks are not required for the course and does not influence any grading**. \n",
    "\n",
    "You can use the *layerVisualization* method also for above models (Q4 and Q5). It will show you the different filter outputs. Again try to understand the features the different filter learn to separate between circles-triangles-rectangles, or the rectangles for the R3 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the CRT dataset (Question 4)\n",
    "x_trn, d_trn, x_val, d_val, width, height = loadImagesCRT()\n",
    "\n",
    "# Load the R3 dataset (Question 5)\n",
    "#x_trn, d_trn, x_val, d_val, width, height = loadImagesR3()\n",
    "\n",
    "print('Training data input shape: ', x_trn.shape)\n",
    "print('Training data output shape: ', d_trn.shape)\n",
    "print('Validation data input shape: ', x_val.shape)\n",
    "print('Validation data output shape: ', d_val.shape)\n",
    "\n",
    "# The size of the images\n",
    "input_shape = (width, height, 1)\n",
    "\n",
    "# Define the CNN ex3\n",
    "ex3 = Sequential()\n",
    "\n",
    "#\n",
    "# YOUR CODE HERE\n",
    "#\n",
    "\n",
    "\n",
    "# We use cross entropy error and the adam optimizer\n",
    "adam = Adam(learning_rate=0.003)\n",
    "ex3.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "ex3.summary()\n",
    "\n",
    "# Now train the ex3\n",
    "estimator_ex3 = ex3.fit(x_trn, d_trn, \n",
    "                      validation_data=(x_val, d_val),\n",
    "                      epochs=50, \n",
    "                      batch_size=50,\n",
    "                      verbose=0)\n",
    "\n",
    "# Training history\n",
    "plt.figure()\n",
    "plt.ylabel('Loss / Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "for k in estimator_ex3.history.keys():\n",
    "    plt.plot(estimator_ex3.history[k], label = k) \n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Training result\n",
    "multi_stat_3(ex3, x_trn, d_trn, 'Training')\n",
    "\n",
    "# Validation result\n",
    "multi_stat_3(ex3, x_val, d_val, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show before or after MaxPooling\n",
    "post_pool = False\n",
    "\n",
    "# The test image to look at\n",
    "idx = 6\n",
    "\n",
    "# Call the visualization method, giving the model and the test data to select the case from\n",
    "layerVisaliztion(ex3, x_val, d_val, idx, post_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex4-1 (#9)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 6-9\n",
    "\n",
    "## RNN as a pulse converter\n",
    "We will now look at recurrent networks! **Note**: This exercise is divided into three cells. The actual questions for this part can be found in cell *Ex4-3* below.\n",
    "\n",
    "### Loading and visualizing the data\n",
    "The cell below loads the training data and the validation data from existing binary python files and plots one set of training/validation data, both the input sequence and the target sequence. Run the cell by entering into the cell and press \"CTRL Enter\".\n",
    "\n",
    "How is data generated? The input sequence consists of square pulses with varying length and height. The waiting time between the pulses is also varying within some predefined ranges. The lower limit is 2 times the length of the previous pulse. The target triangle pulse sequence is built from the input sequence as follows:\n",
    "* the triangle pulse starts when the input square pulse have ended.\n",
    "* the width of the triangle (at the base) is twice the width of the square pulse.\n",
    "* the height of the triangle is the same as the height of the square pulse.\n",
    "\n",
    "The task is now to learn this mapping using a recurrent neural network. There are 500 input/target sequences in the training data and 500 in the validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load data from files\n",
    "x_trn,d_trn= np.load(\"pulsedata1-trn.npy\")\n",
    "x_val,d_val = np.load(\"pulsedata1-val.npy\")\n",
    "\n",
    "\n",
    "print('Training data input shape: ', x_trn.shape)\n",
    "print('Training data output shape: ', d_trn.shape)\n",
    "print('Validation data input shape: ', x_val.shape)\n",
    "print('Validation data output shape: ', d_val.shape)\n",
    "\n",
    "# If this is set to True, then we have the reverse problem. Input triangle pulse, target square puls.\n",
    "if False:\n",
    "    d_trn,x_trn = x_trn[:,::-1],d_trn[:,::-1]\n",
    "    d_val,x_val = x_val[:,::-1],d_val[:,::-1]\n",
    "\n",
    "ns,tlen = x_trn.shape\n",
    "t = np.arange(tlen)\n",
    "\n",
    "# The training / test case to look at\n",
    "i = 3\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(t,x_trn[i,:])\n",
    "plt.legend(['Training, input sequence'], loc=0)\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(t,d_trn[i,:])\n",
    "plt.legend(['Training, target sequence'], loc=0)\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(t,x_val[i,:])\n",
    "plt.legend(['Validation, input sequence'], loc=0)\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(t,d_val[i,:])\n",
    "plt.legend(['Validation, target sequence'], loc=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex4-2 (#10)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 6-9\n",
    "\n",
    "## RNN as a pulse converter\n",
    "### Define the model and train\n",
    "Here we are going to setup the model and train it. There are three different models to choose from: \n",
    "* SimpleRNN: Simple feedback weights where the output from a node is feeding back to itself. For several hidden nodes there are feedback weights to all other nodes in the layer.\n",
    "* LSTM: The LSTM unit\n",
    "* GRU: The GRU unit\n",
    "\n",
    "The standard choice of activation function is *tanh*, but you can also test *relu*. When it comes to training this model we are going to use a possible truncated BPTT approach. The support in Keras for doing this is somewhat limited so here it is implemented manually. In short we have 500 training sequences and we define a mini-batch size *mb* that selects *mb* of these sequences to train using the normal stochastic gradient descent idea. Then we have a variable *batchlen* that is the length of the sequence to use in truncated BPTT. The default values for these are *mb=20* and *batchlen=50*. If you want to train without the truncated BPTT approach put *batchlen=100*.\n",
    "\n",
    "During training we print the normalized training and validation error. Normalized means here that the loss (=MSE) is divided by the variance of the target signal. That means that a normalized error of 1 is poor, but below 0.1 (or so) the error is much smaller than the signal itself.\n",
    "\n",
    "What you need to do in this cell is to define your model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ns,tlen = x_trn.shape\n",
    "\n",
    "# Parameters defining the mini-batch size and \n",
    "# the sequence length for truncated BPTT\n",
    "mb = 20\n",
    "batchlen = 50\n",
    "\n",
    "# The network type\n",
    "net = SimpleRNN\n",
    "#net = GRU\n",
    "#net = LSTM\n",
    "\n",
    "# Number of hidden nodes\n",
    "nh1 = 5\n",
    "\n",
    "# This is only if you would like to add an additional hidden layer. See below.\n",
    "nh2 = 5\n",
    "\n",
    "# The activation function\n",
    "activation = 'tanh'\n",
    "#activation = 'relu'\n",
    "\n",
    "# The number of epochs\n",
    "nE = 20\n",
    "\n",
    "# Start defining the model\n",
    "nmb = ns//mb\n",
    "ntsteps = tlen//batchlen\n",
    "\n",
    "model = Sequential()\n",
    "model.add(net(nh1, \n",
    "              batch_input_shape=(mb,batchlen,1), \n",
    "              stateful=True, \n",
    "              return_sequences=True, \n",
    "              activation=activation))\n",
    "\n",
    "# Uncomment this line if you want to add an additional hidden layer\n",
    "#model.add(net(nh2, stateful=True, return_sequences=True, activation=activation))\n",
    "\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "adam = Adam(learning_rate=0.003)\n",
    "model.compile(optimizer=adam,loss='mean_squared_error')\n",
    "model.summary()\n",
    "\n",
    "# Now the training part\n",
    "trnTrgVar = np.var(d_trn[:,:])   # Variance for train target signal\n",
    "valTrgVar = np.var(d_val[:,:])   # Variance for validation target signal\n",
    "ndone = 0\n",
    "\n",
    "print('Epoch', 'Time/Epoch', ' Trn-Err', '    Val-Err')\n",
    "for ne in range(nE):\n",
    "    t0 = time.time()\n",
    "    sumlossTrn = 0\n",
    "    for batch in range(nmb):\n",
    "        i1,i2 = batch*mb,(batch+1)*mb\n",
    "        model.reset_states()\n",
    "        for tstep in range(ntsteps):\n",
    "            t1,t2 = tstep*batchlen,(tstep+1)*batchlen\n",
    "            loss = model.train_on_batch(x_trn[i1:i2,t1:t2,None], d_trn[i1:i2,t1:t2,None])\n",
    "            sumlossTrn += loss\n",
    "    meanlossTrn = sumlossTrn/(nmb*ntsteps)\n",
    "\n",
    "    # Validation error\n",
    "    sumlossVal = 0\n",
    "    for batch in range(nmb):\n",
    "        i1,i2 = batch*mb,(batch+1)*mb\n",
    "        model.reset_states()\n",
    "        for tstep in range(ntsteps):\n",
    "            t1,t2 = tstep*batchlen,(tstep+1)*batchlen\n",
    "            loss = model.evaluate(x_val[i1:i2,t1:t2,None], d_val[i1:i2,t1:t2,None],batch_size=mb,verbose=0)\n",
    "            sumlossVal += loss\n",
    "    meanlossVal = sumlossVal/(nmb*ntsteps)\n",
    "    t1 = time.time()\n",
    "    ndone += 1\n",
    "    print(ndone, \"    {:.2f}        {:.5f}     {:.5f}\".format(t1-t0, meanlossTrn/trnTrgVar, meanlossVal/valTrgVar))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex4-3 (#11)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 6-9\n",
    "\n",
    "## RNN as a pulse converter\n",
    "### Plot the result\n",
    "In this cell we just plot the result for one of the first *mb* (minibatch size) test sequences. You can select which of these ones by an index (see the code). Also, the last graph shows the hidden node activation for all of the hidden nodes. **Note:** For the GRU and simpleRNN models this is all of the hidden activity there is, but for the LSTM there is also the memory signal. That one is not shown!\n",
    "\n",
    "### Questions\n",
    "We are now finally at the point of asking questions. Whenever you define a new model and train it, you need to run the  cell below in order to show the result for the newly trained model. \n",
    "\n",
    "**Hint!** For all of the questions below you are going to train different models. Keep an eye on how the training error is developing. If you see large fluctuations, you may to change the learning rate. The default value of 0.003 should be OK for most trainings. \n",
    "\n",
    "#### Question 6\n",
    "(Just to get started!) Define a simpleRNN model with 5 hidden nodes and train it for about 20 epochs. **What validation error do you obtain?** \n",
    "\n",
    "Hint 1: The validation error can be found during \"training\" as the error for the last epoch.<br>\n",
    "Hint 2: You may have to train a couple of times to make sure that you did not end up in a \"bad\" local minima the first time.\n",
    "\n",
    "#### Question 7\n",
    "Test different models! Train the three different models (one hidden layer only) with the approximately the same number of trainable weights (around 150-200) and decide which of them that works best? **So, out of the three different models, *simpleRNN, GRU* and *LSTM*, which one worked best using the same number weights?**\n",
    "\n",
    "#### Question 8\n",
    "Interpretation! You are now going to interpret the hidden node outputs. Remember that the actual output for each time is a linear combination of the hidden node outputs. As said before you can see the hidden nodes output in the last plot. Note that the weights in the dense layer can have different signs so that hidden nodes outputs can be linearly combined with both positive and negatives signs. Train a *GRU* model with 3 hidden nodes for about 20 epochs. **Try to explain what the different hidden nodes are detecting**.\n",
    "\n",
    "Comment: This is of course a question with no definite true answer. We just want you to interpret what the different nodes are doing.\n",
    "\n",
    "#### Question 9\n",
    "If you look at the top of cell *Ex4-1* you can, by changing False -> True, define the reverse problem (see top of the code cell). That is, input is the triangle pulse and target is the square pulse. This should be a more difficult problem! **Why?** **Present a RNN model that can \"solve\" this reverse problem (i.e. below 0.1 in test error).**\n",
    "\n",
    "Hint: Here you can experiment with two hidden layers of LSTM/GRU/SimpleRNN nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xshow = x_val[:mb]\n",
    "dshow = d_val[:mb]\n",
    "dout = np.zeros((mb,tlen))\n",
    "hidden1 = np.zeros((mb,tlen,nh1))\n",
    "hidden2 = np.zeros((mb,tlen,nh2))\n",
    "\n",
    "rnn1 = model.layers[0]\n",
    "rnn2= model.layers[1]\n",
    "\n",
    "#dense = model.layers[-1]\n",
    "#sign = K.sign(dense.layer.kernel)[None,None,:,0]\n",
    "if len(model.layers) > 2 :\n",
    "    intermediate = K.function([rnn1.input], [rnn1.output, rnn2.output ])\n",
    "else :\n",
    "    intermediate = K.function([rnn1.input], [rnn1.output])\n",
    "\n",
    "for tstep in range(ntsteps):\n",
    "    t1,t2 = tstep*batchlen,(tstep+1)*batchlen\n",
    "    inp = xshow[:,t1:t2,None]\n",
    "    if len(model.layers) > 2 :\n",
    "        hi,hi2 = intermediate([inp])\n",
    "        hidden2[:,t1:t2:,:] = hi2\n",
    "    else :\n",
    "        hi, = intermediate([inp])\n",
    "    hidden1[:,t1:t2:,:] = hi\n",
    "    yi = model.predict(xshow[:,t1:t2,None], verbose=0)\n",
    "    dout[:,t1:t2] = yi[:,:,0]\n",
    "\n",
    "t = np.arange(tlen)\n",
    "\n",
    "# Selection of validation sequence, valid range is [0,mb]\n",
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(t,xshow[i],'-',marker='.')\n",
    "plt.legend(['Test, input sequence'], loc=0)\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(t,dshow[i],'-',marker='.')\n",
    "plt.plot(t,dout[i],'-',marker='.')\n",
    "plt.legend(['Test, target sequnce', 'Test, predicted sequence'], loc=0)\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(t,hidden1[i],'-',marker='.')\n",
    "plt.title('Hidden 1 node outputs')\n",
    "\n",
    "if len(model.layers) > 2 :\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(t,hidden2[i],'-',marker='.')\n",
    "    plt.title('Hidden 2 node outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The report!\n",
    "We have added intructions inside this report template. As you write your report, remove the instructions.\n",
    "\n",
    "## Name\n",
    "\n",
    "## Introduction\n",
    "A few sentences about the overall theme of the exercise.\n",
    "\n",
    "## Answers to questions\n",
    "Provide enough information to clarify the meaning of your answers, so that they can be understood by someone who does not scroll up and read the entire instruction.\n",
    "\n",
    "The questions are repeated here, for clarity of what is demanded. If it does not fit your style to quote them verbatim, change the format.\n",
    "\n",
    "#### Question 1\n",
    "What is your validation set performance in terms of the accuracy?\n",
    "\n",
    "#### Question 2\n",
    "How many parameters do you have in your trimmed model? What is your architecture?\n",
    "\n",
    "#### Question 3\n",
    "Can you find and describe some property in the filters that makes sense when it comes to separating \"5\" from \"6\"?\n",
    "\n",
    "#### Question 4\n",
    "Provide the details of your CNN model for the CRT problem and present the validation result.\n",
    "\n",
    "#### Question 5\n",
    "Provide the details of your CNN model for the R3 problem and present the validation result.<br>\n",
    "Why is this a more difficult problem than Question 4?\n",
    "\n",
    "#### Question 6\n",
    "What validation error do you obtain?\n",
    "\n",
    "#### Question 7\n",
    "Present three different models, *simpleRNN, GRU* and *LSTM*, using roughly the same number weights.<br>\n",
    "Which one worked best?\n",
    "\n",
    "#### Question 8\n",
    "Try to explain what the different hidden nodes are detecting. *Comment: This is of course a question with no definite true answer. We just want you to interpret what the different nodes are doing.*\n",
    "\n",
    "#### Question 9\n",
    "Why is the reverse of the pulse problem (input signal and target signal change roles, time is reversed) more difficult? <br>\n",
    "Present a RNN model that can \"solve\" this reverse problem (i.e. below 0.1 in test error).\n",
    "\n",
    "\n",
    "## Summary\n",
    "Connect the summary to your introduction, to provide a brief overview of your findings.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
